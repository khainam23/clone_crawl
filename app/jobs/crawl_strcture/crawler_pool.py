"""
Crawler Pool - Quáº£n lÃ½ pool cÃ¡c crawler instances Ä‘á»ƒ trÃ¡nh overhead
"""

import asyncio
from typing import Optional, Callable, List
from crawl4ai import AsyncWebCrawler
from app.core.config import CrawlerConfig
from .custom_rules import CustomExtractor


class CrawlerPool:
    """
    Pool quáº£n lÃ½ cÃ¡c AsyncWebCrawler instances Ä‘á»ƒ tÃ¡i sá»­ dá»¥ng
    GiÃºp trÃ¡nh overhead khi khá»Ÿi táº¡o crawler má»›i cho má»—i request
    """
    
    def __init__(
        self, 
        pool_size: int,
        custom_extractor_factory: Optional[Callable[[], CustomExtractor]] = None
    ):
        """
        Initialize CrawlerPool
        
        Args:
            pool_size: Sá»‘ lÆ°á»£ng crawler instances trong pool (thÆ°á»ng báº±ng BATCH_SIZE)
            custom_extractor_factory: Optional factory function to create custom extractor
        """
        self.pool_size = pool_size
        self.config = CrawlerConfig()
        self.custom_extractor_factory = custom_extractor_factory
        
        # Pool cá»§a cÃ¡c crawler instances
        self._crawlers: List[AsyncWebCrawler] = []
        self._available_crawlers: asyncio.Queue = asyncio.Queue()
        self._initialized = False
        self._lock = asyncio.Lock()
        
    async def initialize(self):
        """
        Khá»Ÿi táº¡o pool vá»›i sá»‘ lÆ°á»£ng crawler instances
        """
        async with self._lock:
            if self._initialized:
                return
                
            print(f"ðŸ”§ Initializing crawler pool with {self.pool_size} instances...")
            
            for i in range(self.pool_size):
                try:
                    crawler = AsyncWebCrawler(config=self.config.BROWSER_CONFIG)
                    await crawler.__aenter__()  # Initialize crawler context
                    self._crawlers.append(crawler)
                    await self._available_crawlers.put(crawler)
                    print(f"âœ… Crawler {i+1}/{self.pool_size} initialized")
                except Exception as e:
                    print(f"âŒ Failed to initialize crawler {i+1}: {e}")
                    
            self._initialized = True
            print(f"ðŸŽ‰ Crawler pool initialized with {len(self._crawlers)} instances")
    
    async def acquire(self) -> AsyncWebCrawler:
        """
        Láº¥y má»™t crawler instance tá»« pool
        Náº¿u pool Ä‘ang trá»‘ng, sáº½ Ä‘á»£i cho Ä‘áº¿n khi cÃ³ crawler available
        
        Returns:
            AsyncWebCrawler instance
        """
        if not self._initialized:
            await self.initialize()
            
        crawler = await self._available_crawlers.get()
        return crawler
    
    async def release(self, crawler: AsyncWebCrawler):
        """
        Tráº£ crawler instance vá» pool sau khi sá»­ dá»¥ng xong
        
        Args:
            crawler: AsyncWebCrawler instance to release
        """
        await self._available_crawlers.put(crawler)
    
    async def close(self):
        """
        ÄÃ³ng táº¥t cáº£ crawler instances trong pool
        """
        async with self._lock:
            if not self._initialized:
                return
                
            print(f"ðŸ”’ Closing crawler pool...")
            
            # ÄÃ³ng táº¥t cáº£ crawlers
            for i, crawler in enumerate(self._crawlers):
                try:
                    await crawler.__aexit__(None, None, None)
                    print(f"âœ… Crawler {i+1}/{len(self._crawlers)} closed")
                except Exception as e:
                    print(f"âš ï¸ Error closing crawler {i+1}: {e}")
            
            self._crawlers.clear()
            
            # Clear queue
            while not self._available_crawlers.empty():
                try:
                    self._available_crawlers.get_nowait()
                except asyncio.QueueEmpty:
                    break
                    
            self._initialized = False
            print(f"ðŸŽ‰ Crawler pool closed")
    
    async def __aenter__(self):
        """Context manager entry"""
        await self.initialize()
        return self
    
    async def __aexit__(self, exc_type, exc_val, exc_tb):
        """Context manager exit"""
        await self.close()
    
    def get_custom_extractor(self) -> CustomExtractor:
        """
        Táº¡o custom extractor instance
        
        Returns:
            CustomExtractor instance
        """
        if self.custom_extractor_factory:
            return self.custom_extractor_factory()
        else:
            return CustomExtractor()