# Tokyu Crawl Page Module

## ğŸ“‹ Overview

This module handles crawling property listings from Tokyu real estate website. It extracts comprehensive property information including building details, unit specifications, rental costs, and amenities.

## ğŸ—ï¸ Structure

```
tokyu_crawl_page/
â”œâ”€â”€ index.py                      # Entry point for crawling
â”œâ”€â”€ custom_extractor_factory.py  # Factory for creating extractors
â”œâ”€â”€ property_data_extractor.py   # Main data extraction logic
â”œâ”€â”€ image_extractor.py            # Image extraction
â”œâ”€â”€ map_extractor.py              # Map/coordinates extraction
â”œâ”€â”€ constants.py                  # Configuration constants
â””â”€â”€ Readme.md                     # This file
```

## âœ¨ Optimized Features

### 1. **Helper Methods Pattern**
- `_find_dt_dd()`: Extract content from `<dt>label</dt><dd>content</dd>` pattern
- `_find_td()`: Extract content from table `<th>label</th>...<td>content</td>` pattern
- Eliminates repetitive HTML parsing code
- Centralized HTML cleaning and extraction

### 2. **Clear Processing Pipeline**
The extraction process follows a well-defined 13-step pipeline:

```
1. Clean HTML â†’ Store in _html field
2. Extract Images
3. Extract Building Info (name, type, structure, address, year)
4. Extract Unit Info (unit_no, floor, size, direction)
5. Extract Rental Costs (monthly_rent, monthly_maintenance)
6. Extract Other Fees (cleaning fee, other expenses)
7. Extract Unit Description (pet info, remarks)
8. Extract Deposits & Fees (deposit, key money, renewal)
9. Extract Amenities (from è¨­å‚™ãƒ»æ¡ä»¶ section)
10. Extract Pet Policy (from æ•·é‡‘ç©å¢— section)
11. Set Default Amenities
12. Calculate Financial Info (guarantor, agency, insurance, discount)
13. Extract Map Coordinates
14. Cleanup Temporary Fields
```

### 3. **Enhanced Error Handling**
- HTTP timeout support (30 seconds)
- Per-page error handling in listing crawl
- Safe wrapper for each extraction step
- Graceful degradation on failures

### 4. **Improved Logging**
- Emoji indicators for better visibility (ğŸš€, ğŸ“„, âœ…, âš ï¸, ğŸ‰)
- Clear progress tracking
- Detailed extraction logs with values

## ğŸ“Š Data Extraction

### Building Information
- **building_name_ja**: Building name in Japanese (ç‰©ä»¶å)
- **building_type**: Type of building (ç¨®åˆ¥)
- **structure**: Building structure (å»ºç‰©æ§‹é€ )
- **address**: Full address (æ‰€åœ¨åœ°)
- **year**: Construction year (ç¯‰å¹´æœˆ)

### Unit Information
- **unit_no**: Room number (éƒ¨å±‹ç•ªå·)
- **floor_no**: Floor number (æ‰€åœ¨éš)
- **floors**: Total floors (éšå»º)
- **size**: Unit size in mÂ² (å°‚æœ‰é¢ç©)
- **direction**: Facing direction (æ–¹ä½)

### Rental Costs
- **monthly_rent**: Monthly rent (è³ƒæ–™)
- **monthly_maintenance**: Maintenance fee (ç®¡ç†è²»ãƒ»å…±ç›Šè²»)
- **numeric_deposit**: Deposit amount (æ•·é‡‘)
- **numeric_security_deposit**: Security deposit (ä¿è¨¼é‡‘)
- **numeric_key**: Key money (ç¤¼é‡‘)
- **numeric_deposit_amortization**: Deposit amortization (å„Ÿå´ãƒ»æ•·å¼•)
- **numeric_renewal**: Renewal fee (æ›´æ–°æ–™)

### Additional Fees
- **other_initial_fees**: Cleaning fee (æ¸…æƒè²»)
- **fire_insurance**: Fire insurance (ä¿é™ºæ–™)
- **numeric_discount**: Free rent discount (ãƒ•ãƒªãƒ¼ãƒ¬ãƒ³ãƒˆ)
- **numeric_agency**: Agency fee (calculated as 1.1 Ã— monthly_rent)
- **numeric_guarantor**: Guarantor fee (50% of total monthly)
- **numeric_guarantor_max**: Max guarantor fee (100% of total monthly)

### Other Information
- **property_description_ja**: Property description (ãƒšãƒƒãƒˆå¯åŒºåˆ† + å‚™è€ƒ)
- **property_other_expenses_ja**: Other expenses description
- **available_from**: Move-in date (å…¥å±…å¯èƒ½æ—¥)
- **pets**: Pet policy (Y/N)
- **amenities**: Various amenities flags

## ğŸš€ Usage

```python
from app.jobs.tokyu_crawl_page.index import crawl_multi

# Run the crawler
await crawl_multi()
```

## ğŸ”§ Configuration

Edit `constants.py` to configure:
- `URL_MULTI`: Base URL for listing pages
- `ITEM_SELECTOR`: CSS selector for property items
- `NUM_PAGES`: Number of pages to crawl
- `BASE_URL`: Base URL for building full URLs
- `DEFAULT_AMENITIES`: Default amenity values

## ğŸ“ Code Optimization Summary

### Before Optimization
- âŒ Repetitive HTML extraction code
- âŒ Scattered error handling
- âŒ Unclear processing order
- âŒ Basic logging
- âŒ No timeout handling

### After Optimization
- âœ… Helper methods for common patterns
- âœ… Centralized error handling with safe wrappers
- âœ… Well-documented processing pipeline
- âœ… Enhanced logging with emoji indicators
- âœ… Timeout and error recovery
- âœ… Cleaner, more maintainable code
- âœ… ~50+ lines of code eliminated

## ğŸ¯ Key Improvements

1. **Code Reduction**: Eliminated ~50+ lines through helper methods
2. **Maintainability**: Easier to add/modify extraction logic
3. **Reliability**: Better error handling and recovery
4. **Readability**: Clear structure with inline documentation
5. **Performance**: Optimized HTML parsing with helper methods

## ğŸ” Processing Flow

```
index.py
  â””â”€> _fetch_page_urls()
       â”œâ”€> Fetch listing pages (1 to NUM_PAGES)
       â”œâ”€> Extract property URLs
       â””â”€> Return list of URLs
  â””â”€> crawl_pages()
       â””â”€> For each URL:
            â””â”€> custom_extractor_factory.setup_custom_extractor()
                 â”œâ”€> Pre-hook: _pass_html() - Clean HTML
                 â””â”€> Post-hooks: 13 extraction steps
                      â””â”€> Each wrapped with _create_safe_wrapper()
```

## ğŸ“Œ Notes

- All extraction methods follow the pattern: `(data: Dict, html: str) -> Dict`
- Helper methods are prefixed with `_` to indicate private usage
- Processing order is critical (e.g., rental costs must be extracted before calculating deposits)
- Station extraction is currently commented out (optional feature)
- Temporary `_html` field is cleaned up at the end of processing

## ğŸ› Debugging

To debug extraction issues:

1. Check the HTML structure matches the expected pattern
2. Verify the Japanese labels in `_find_dt_dd()` and `_find_td()` calls
3. Review logs for specific extraction step failures
4. Test individual extraction methods with sample HTML

## ğŸ”„ Future Enhancements

- [ ] Add retry logic for failed extractions
- [ ] Implement extraction success rate tracking
- [ ] Create base extractor class for shared functionality
- [ ] Add unit tests for extraction methods
- [ ] Support for additional property types