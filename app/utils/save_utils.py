"""
File operation utility functions
"""
import logging, time
from typing import List, Dict, Any, Optional
import logging, time, json, os

from app.db.mongodb import get_collection

# Setup logger
logger = logging.getLogger(__name__)

class SaveUtils:
    """Utility functions cho file operations"""
    
    @staticmethod
    async def backup_db(collection_name: Optional[str] = "crawl_results") -> Optional[str]:
        """Backup MongoDB collection ra file JSON tr∆∞·ªõc khi th·ª±c hi·ªán thao t√°c"""
        try:
            collection = get_collection(collection_name)
            
            # ƒê·∫øm s·ªë l∆∞·ª£ng documents
            count = await collection.count_documents({})
            
            if count == 0:
                logger.info(f"No data to backup in collection: {collection_name}")
                return None
            
            # L·∫•y t·∫•t c·∫£ documents t·ª´ collection
            cursor = collection.find({})
            documents = await cursor.to_list(length=None)
            
            # T·∫°o th∆∞ m·ª•c backup n·∫øu ch∆∞a t·ªìn t·∫°i
            backup_dir = "data/backups"
            if not os.path.exists(backup_dir):
                os.makedirs(backup_dir)
            
            # T·∫°o t√™n file backup v·ªõi timestamp
            timestamp = int(time.time())
            filename = f"{backup_dir}/{collection_name}_backup_{timestamp}.json"
            
            # L∆∞u v√†o file JSON
            with open(filename, 'w', encoding='utf-8') as f:
                json.dump(documents, f, ensure_ascii=False, indent=2, default=str)
            
            logger.info(f"Backed up {count} documents from collection '{collection_name}' to: {filename}")
            
            return filename
            
        except Exception as e:
            logger.error(f"Error backing up MongoDB collection {collection_name}: {e}")
            print(f"‚ùå Error backing up MongoDB collection {collection_name}: {e}")
            return None
    
    @staticmethod
    async def clean_db(collection_name: Optional[str] = "crawl_results", auto_backup: bool = True):
        """L√†m r·ªóng database theo collection_name"""
        try:
            # T·ª± ƒë·ªông backup tr∆∞·ªõc khi x√≥a (n·∫øu auto_backup=True)
            if auto_backup:
                backup_file = await SaveUtils.backup_db(collection_name)
                if backup_file:
                    print(f"‚úÖ Backup completed before cleaning")
            
            collection = get_collection(collection_name)
            
            # X√≥a t·∫•t c·∫£ documents trong collection
            delete_result = await collection.delete_many({})
            deleted_count = delete_result.deleted_count
            
            logger.info(f"Cleaned {deleted_count} documents from MongoDB collection: {collection_name}")
            print(f"üßπ Cleaned {deleted_count} documents from MongoDB collection: {collection_name}")
            
            return deleted_count
            
        except Exception as e:
            logger.error(f"Error cleaning MongoDB collection {collection_name}: {e}")
            print(f"‚ùå Error cleaning MongoDB collection {collection_name}: {e}")
            return None
        
    @staticmethod
    async def filter_urls(urls: List[str], collection_name: Optional[str] = "crawl_results", id_fallback: Optional[int] = 0) -> tuple[List[str], int]:
        """
        L·ªçc ra c√°c URLs ch∆∞a t·ªìn t·∫°i trong collection v√† l·∫•y ID l·ªõn nh·∫•t
        
        Args:
            urls: Danh s√°ch URLs c·∫ßn ki·ªÉm tra
            collection_name: T√™n collection c·∫ßn ki·ªÉm tra
            
        Returns:
            Tuple g·ªìm (danh s√°ch URLs ch∆∞a t·ªìn t·∫°i, ID MongoDB l·ªõn nh·∫•t hi·ªán t·∫°i)
        """
        try:
            collection = get_collection(collection_name)
            
            # L·∫•y ID l·ªõn nh·∫•t hi·ªán t·∫°i trong collection
            max_id_doc = await collection.find_one(
                sort=[("_id", -1)],
                projection={"_id": 1}
            )
            max_id = max_id_doc["_id"] if max_id_doc else id_fallback
            
            if not urls:
                return [], max_id
            
            # T·∫°o index cho field 'link' n·∫øu ch∆∞a c√≥ (ƒë·ªÉ tƒÉng t·ªëc ƒë·ªô query)
            try:
                await collection.create_index("link")
            except Exception as e:
                logger.warning(f"Index creation skipped or failed: {e}")
            
            # T√¨m c√°c URLs ƒë√£ t·ªìn t·∫°i trong collection
            existing_urls = await collection.distinct("link", {"link": {"$in": urls}})
            existing_urls_set = set(existing_urls)
            
            # L·ªçc ra c√°c URLs ch∆∞a t·ªìn t·∫°i
            new_urls = [url for url in urls if url not in existing_urls_set]
            
            logger.info(f"Filtered URLs: {len(urls)} total, {len(existing_urls_set)} existing, {len(new_urls)} new | Max ID: {max_id}")
            print(f"üîç Filtered URLs: {len(urls)} total, {len(existing_urls_set)} existing, {len(new_urls)} new | Max ID: {max_id}")
            
            return new_urls, max_id
            
        except Exception as e:
            logger.error(f"Error filtering URLs from collection {collection_name}: {e}")
            print(f"‚ùå Error filtering URLs: {e}")
            # Tr·∫£ v·ªÅ t·∫•t c·∫£ URLs v√† ID = 0 n·∫øu c√≥ l·ªói (fail-safe)
            return urls, id_fallback
    
    @staticmethod
    async def save_db_results(results: List[Dict[str, Any]], collection_name: Optional[str] = "crawl_results", _id: Optional[int] = 0) -> Optional[str]:
        """L∆∞u k·∫øt qu·∫£ v√†o MongoDB"""        
        try:
            collection = get_collection(collection_name)
        
            # Chu·∫©n b·ªã documents ƒë·ªÉ insert
            documents = []
            for i, result in enumerate(results):
                document = {
                    **result,
                    "created_date": time.time(),
                    "_id": _id + i + 1
                }
                
                documents.append(document)
            
            # Insert v√†o MongoDB
            if documents:
                insert_result = await collection.insert_many(documents)
                inserted_count = len(insert_result.inserted_ids)
                
                logger.info(f"Saved {inserted_count} results to MongoDB collection: {collection_name}")
                print(f"üíæ Saved {inserted_count} results to MongoDB collection: {collection_name}")
                return f"{collection_name}"
            else:
                logger.warning("No results to save")
                print("‚ö†Ô∏è No results to save")
                return None
            
        except Exception as e:
            logger.error(f"Error saving to MongoDB collection {collection_name}: {e}")
            print(f"‚ùå Error saving to MongoDB: {e}")
            return None
        
    @staticmethod
    async def save_json_results(results: List[Dict[str, Any]], collection_name: Optional[str] = "crawl_results", _id: Optional[int] = 0) -> Optional[str]:
        try:
            # T·∫°o th∆∞ m·ª•c data n·∫øu ch∆∞a t·ªìn t·∫°i
            data_dir = "data"
            if not os.path.exists(data_dir):
                os.makedirs(data_dir)
            
            # T·∫°o t√™n file d·ª±a tr√™n collection_name v√† timestamp
            timestamp = int(time.time())
            filename = f"{data_dir}/{collection_name}_{timestamp}.json"
            
            # Chu·∫©n b·ªã documents ƒë·ªÉ l∆∞u
            documents = []
            for i, result in enumerate(results):
                document = {
                    **result,
                    "created_date": time.time(),
                    "_id": str(_id + i + 1)
                }
                documents.append(document)
            
            # L∆∞u v√†o file JSON
            if documents:
                with open(filename, 'w', encoding='utf-8') as f:
                    json.dump(documents, f, ensure_ascii=False, indent=2)
                
                saved_count = len(documents)
                logger.info(f"Saved {saved_count} results to JSON file: {filename}")
                print(f"üíæ Saved {saved_count} results to JSON file: {filename}")
                return filename
            else:
                logger.warning("No results to save")
                print("‚ö†Ô∏è No results to save")
                return None
                
        except Exception as e:
            logger.error(f"Error saving to JSON file: {e}")
            print(f"‚ùå Error saving to JSON file: {e}")
            return None
        